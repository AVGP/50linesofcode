<h1>Easy scaling with Docker, HAProxy and confd</h1><p>2014-07-02 13:30:31 GMT</p><article><h1>TL;DR</h1>

<p>Forrest is a very small shell script that binds together etcd and docker to allow easy scaling - for example with the combination of etcd + confd + HAProxy + Docker you can quickly and easily spin up a new web server instance and hook it into your load balancer.</p>

<p><a href="https://www.youtube.com/watch?v=sbr6GwQbJc4">Here&rsquo;s also a video of that scenario</a></p>

<h2>Preface</h2>

<p>One of the most powerful advantages of the cloud computing era is the ability to quickly scale up and down as needed - particulary handy if you have viral marketing in place and you just don&rsquo;t know if and when it hits your servers.</p>

<p>So far that meant to spin up a full virtual instance (e.g. an Amazon instance or a droplet on Digital Ocean) but with lightweight isolations like <a href="http://www.docker.com">Docker</a> (which is based on <a href="https://linuxcontainers.org/">LXC</a>) we can easily package and distribute applications, start and stop them as needed.</p>

<p>In this post I will give an example of a very simple Go application that responds to HTTP requests with a simple string.</p>

<p>This application will be served behind an HAProxy as a reverse proxy (and a load balancer). Forrest is using etcd and confd to allow registering/unregistering new docker containers within HAProxy, so that traffic will automatically be routed to the available containers.</p>

<p>In the scenario I will describe in this post, I assume three servers:</p>

<table><thead><tr><th>name</th>
  <th>private IP</th>
  <th>packages</th>
</tr></thead><tbody><tr><td>gw1</td>
  <td>10.10.10.1</td>
  <td>haproxy, confd</td>
</tr><tr><td>docker1</td>
  <td>10.10.10.10</td>
  <td>docker, forrest</td>
</tr><tr><td>etcd1</td>
  <td>10.10.10.20</td>
  <td>etcd</td>
</tr></tbody></table><p>The private IPs allow the servers to communicate with each other, without exposing this communication interface to the public internet.</p>

<p>If you <strong>don&rsquo;t have a private network</strong> between your servers for whatever reason, make sure to <strong>read the documentation on the different components carefully</strong> to make sure your setup is still secure*</p>

<p>Let&rsquo;s start with etcd.</p>

<h2>etcd</h2>

<p><a href="https://github.com/coreos/etcd">etcd</a> is a key/value store, basically.
It allows easy storage of configuration values in a central place, using a simple REST-API.</p>

<p>For example we could store our servers with a name and an IP like this:</p>

<pre><code>$ curl -XPUT <a href="http://10.10.10.20:4001/v2/keys/app/servers/web1">http://10.10.10.20:4001/v2/keys/app/servers/web1</a> -d value="10.10.10.10:45679"
</code></pre>

<p>and then get the value with</p>

<pre><code>$ curl <a href="http://10.10.10.20:4001/v2/keys/app/servers/web1">http://10.10.10.20:4001/v2/keys/app/servers/web1</a>
</code></pre>

<p>We will use this to store exactly this: Our docker container IPs plus their name, so we can find them automatically as they become available to add them to our reverse proxy as well as remove them from there when they go down.</p>

<p>Let&rsquo;s start etcd:</p>

<pre><code>nohup etcd/bin/etcd -bind-addr=10.10.10.20 &gt; /var/log/etcd.log &amp;
</code></pre>

<h2>confd</h2>

<p>confd is insanely useful, yet surprisingly simple to use.
Basically all it does is watch a config server (<a href="https://github.com/coreos/etcd">etcd</a> or <a href="https://consul.io">Consul</a>) for changes.</p>

<p>If it detects a change, it uses a template to create a new version of a config file with these new values and run a command to reload the configuration (in our case, for instance, <code>service haproxy reload</code>).</p>

<p>This way it allows &ldquo;live&rdquo; configuration changes.</p>

<p>For that to work we need two files: The template and the configuration.
Here is the configuration:</p>

<h3>/etc/confd/conf.d/helloworld.toml</h3>

<pre><code>[template]
src = "haproxy.cfg.tmpl"
dest = "/etc/haproxy/haproxy.cfg"
keys = [
  "/app/servers",
]
reload_cmd = "/usr/sbin/service haproxy reload"
</code></pre>

<p>This defines where the file will be written to (&ldquo;/etc/haproxy/haproxy.cfg&rdquo;), what the template will be (&ldquo;haproxy.cfg.tmpl&rdquo;), what&rsquo;s the root key on where to find the configuration values and the command to run if the config has been rewritten.</p>

<p>A template for HAProxy could look like this:</p>

<h3>/etc/confd/templates/haproxy.cfg.tmpl</h3>

<pre><code>defaults
  log     global
  mode    http

listen frontend 0.0.0.0:8080
  mode http
  stats enable
  stats uri /haproxy?stats
  balance roundrobin
  option httpclose
  option forwardfor
  {{range $server := .app_servers}}
  server {{Base $server.Key}} {{$server.Value}} check
  {{end}}
</code></pre>

<p>That&rsquo;s a very simple HAProxy config that listens on port 8080, gathers and exposes some stats (nice for playing around with it), does a simple roundrobin load balancing.</p>

<p>The last three lines are interesting, as confd comes into play here&hellip;</p>

<p>The <code>{{range $server := .app_servers}}</code> iterates over each key within etcd at the <code>/app/servers</code> path and writes a config line containing <code>server</code> followed by the key name itself and its value.</p>

<p>So if etcd has the following values:</p>

<pre><code>/app/servers/web1      = "10.10.10.10:1234"
/app/servers/web2      = "10.10.10.10:1337"
/app/servers/test_web1 = "10.10.10.10:4242"
</code></pre>

<p>then we would get this config file lines:</p>

<pre><code>server web1 10.10.10.10:1234 check
server web2 10.10.10.10:1337 check
server test_web1 10.10.10.10:4242 check
</code></pre>

<p>which means that HAProxy will balance requests between these 3 servers and performs a health check on each of them.</p>

<p>This way we can now use etcd and confd to dynamically configure our HAProxy via changes in the values stored in the etcd. Neat!</p>

<p>Let&rsquo;s start confd then:</p>

<h3>Starting confd</h3>

<pre><code>nohup confd -verbose -interval 10 -node '10.10.10.20:4001' -confdir /etc/confd &gt; /var/log/confd.log &amp;
</code></pre>

<h2>Docker</h2>

<p>For an in-depth introduction to Docker, check out <a href="http://www.docker.com/tryit/">the incredibly fantastic interactive tutorial on their site</a>.</p>

<p>For this scenario, I will pretend you have a working Docker host and a docker image for your application. I will call that image &lsquo;demo/myapp&rsquo; for now.</p>

<p>The image should only expose a single port.</p>

<h2>Start &amp; Stop with Forrest</h2>

<p>All forrest does is launch (or stop) a container from an image and announce the newly started container, including the Port it exposes, to the etcd.</p>

<p>Thus, it allows us to pick up the <code>address:port</code> combination from the etcd and put it into the configuration of our HAProxy&hellip; which effectively means we&rsquo;re able to automatically add or remove containers from the load balancing as they go up or down.</p>

<p>Now this is how this would look like:</p>

<pre><code>user@docker1: $ export ETCD_HOST="10.10.10.20:4001"
user@docker1: $ export ETCD_PREFIX="app/servers"
user@docker1: $ export FORREST_IP="10.10.10.10" # possibly optional
user@docker1: $ forrest launch demo/myapp
  Launching demo/myapp on 10.10.10.10 ...
  Announcing to 10.10.10.20:4001 ...
  demo/myapp running on Port 49731 with name sharp_mccarthy
user@docker1: $
</code></pre>

<p>And you should now be able to reach this application through the HAProxy on your public IP or domain name.</p>

<p>If you want to stop a running container and remove it from etcd (and thus from the HAProxy) you do</p>

<pre><code>user@docker1: $ forrest stop sharp_mccarthy
  Stopping sharp_mccarthy ...
  Found container 8d3299a3427b ...
  Stopped.
user@docker1: $
</code></pre>

<p>Tada!</p>

<h2>The future</h2>

<p>I&rsquo;m actually using forrest to control a pretty small amount of containers (I used it with ~30 containers a short while ago for fun&amp;profit) and particularly like the possibility to do rolling updates with it (the &ldquo;one - some - many&rdquo; strategy where you try out a new version with only a few request and then ramp it up gently if you&rsquo;re confident).</p>

<p>Obviously this tool isn&rsquo;t made for large scale deployments with a fleet of docker hosts - but I believe that it&rsquo;s a good foundation to build something on top of it.</p>

<p>For instance you could build a simple tool that automatically SSHes into a server from a cluster of docker hosts and launches new instances when load is rising - or you write a small agent that does so&hellip; there are many possibilities.</p></article>